{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for the dataset\n",
    "root = \"data/DressCode/\"\n",
    "\n",
    "# Map labels to their corresponding directories\n",
    "DIRECTORY_MAP = [\"upper_body\", \"lower_body\", \"dresses\"]\n",
    "\n",
    "CLASS_MAP = [0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2]\n",
    "\n",
    "CLASS_TO_NAME = [\"short sleeve top\",\n",
    "\"long sleeve top\",\n",
    "\"short sleeve outwear\"\n",
    "\"long sleeve outwear\",\n",
    "\"vest\",\n",
    "\"sling\",\n",
    "\"shorts\",\n",
    "\"trousers\",\n",
    "\"skirt\",\n",
    "\"short sleeve dress\",\n",
    "\"long sleeve dress\",\n",
    "\"vest dress\",\n",
    "\"sling dress\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>garment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000_0.jpg</td>\n",
       "      <td>000000_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001_0.jpg</td>\n",
       "      <td>000001_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000002_0.jpg</td>\n",
       "      <td>000002_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000003_0.jpg</td>\n",
       "      <td>000003_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004_0.jpg</td>\n",
       "      <td>000004_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model       garment  label\n",
       "0  000000_0.jpg  000000_1.jpg      0\n",
       "1  000001_0.jpg  000001_1.jpg      0\n",
       "2  000002_0.jpg  000002_1.jpg      0\n",
       "3  000003_0.jpg  000003_1.jpg      0\n",
       "4  000004_0.jpg  000004_1.jpg      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset\n",
    "pairs = pd.read_csv(\n",
    "    os.path.join(root, \"train_pairs_cropped.txt\"),\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"model\", \"garment\", \"label\"],\n",
    ")\n",
    "\n",
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the encoder network\n",
    "encoder = models.resnet50()\n",
    "\n",
    "# Load the weights\n",
    "encoder.load_state_dict(torch.load(\"models\\ResNet50 Cosine Similarity Margin=1\\checkpoint-3.pt\"))\n",
    "\n",
    "# Send the model to the device\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Define the transformations for the network\n",
    "transforms = transforms.Compose([transforms.Resize((256, 192)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(image: Image) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the features for a given image.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    encoder.eval()\n",
    "\n",
    "    # Resize & convert to tensor\n",
    "    image = transforms(image)\n",
    "\n",
    "    # Add a batch dimension\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        return encoder(image).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Features: 100%|██████████| 48140/48140 [11:17<00:00, 71.01image/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([13498, 1000]),\n",
       " torch.Size([7132, 1000]),\n",
       " torch.Size([27510, 1000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUM_IMAGES x NUM_FEATURES\n",
    "features = {\"upper_body\": [], \"lower_body\": [], \"dresses\": []}\n",
    "feature_indices = {\"upper_body\": [], \"lower_body\": [], \"dresses\": []}\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "for i, (model, garment, label) in tqdm(\n",
    "    enumerate(pairs.values),\n",
    "    desc=\"Calculating Features\",\n",
    "    total=len(pairs),\n",
    "    unit=\"image\",\n",
    "):\n",
    "    # Load in the garment image\n",
    "    garment_image = Image.open(\n",
    "        os.path.join(root, DIRECTORY_MAP[label], \"cropped_images\", garment)\n",
    "    ).convert(\"RGB\")\n",
    "    \n",
    "    # Get the features\n",
    "    features[DIRECTORY_MAP[label]].append(calculate_features(garment_image))\n",
    "    feature_indices[DIRECTORY_MAP[label]].append(i)\n",
    "\n",
    "features[\"upper_body\"] = torch.cat(features[\"upper_body\"])\n",
    "features[\"lower_body\"] = torch.cat(features[\"lower_body\"])\n",
    "features[\"dresses\"] = torch.cat(features[\"dresses\"])\n",
    "\n",
    "feature_indices[\"upper_body\"] = np.array(feature_indices[\"upper_body\"])\n",
    "feature_indices[\"lower_body\"] = np.array(feature_indices[\"lower_body\"])\n",
    "feature_indices[\"dresses\"] = np.array(feature_indices[\"dresses\"])\n",
    "\n",
    "features[\"upper_body\"].shape, features[\"lower_body\"].shape, features[\"dresses\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features\n",
    "torch.save(features, \"data/DressCode/train_features.pt\")\n",
    "torch.save(feature_indices, \"data/DressCode/train_feature_indices.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
