{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transformss\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, garment, label = df.iloc[10]\n",
    "# image = Image.open(os.path.join(\"data/DressCode\", LABEL_MAP[label], \"images\", garment))\n",
    "# image.convert('RGB')\n",
    "# colors = image.getcolors(image.size[0] * image.size[1])\n",
    "# colors\n",
    "# # Diplay colors of image\n",
    "# most_common = max(colors, key=lambda x: x[0])\n",
    "# most_common[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = [\n",
    "    \"upper_body\",\n",
    "    \"lower_body\",\n",
    "    \"dresses\"\n",
    "]\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, root: str, pairs: str) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root = root\n",
    "\n",
    "        # Load in the paired data\n",
    "        self.data = pd.read_csv(pairs, delimiter='\\t', header=None, names=['model', 'garment', 'label'])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "              return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        model, garment, label = self.data.iloc[index]\n",
    "        \n",
    "        # Load the images\n",
    "        anchor = Image.open(os.path.join(self.root, LABEL_MAP[label], \"images\", garment)).convert(\"RGB\")\n",
    "        positive = Image.open(os.path.join(self.root, LABEL_MAP[label], \"images\", model)).convert(\"RGB\")\n",
    "        \n",
    "        # Load the negative image\n",
    "        negative_index = random.randrange(0, len(self.data))\n",
    "        negative_model, negative_garment, negative_label = self.data.iloc[negative_index]\n",
    "        negative = Image.open(os.path.join(self.root, LABEL_MAP[negative_label], \"images\", negative_model)).convert(\"RGB\")\n",
    "\n",
    "        # Convert images to tensors\n",
    "        convert_tensor = transformss.ToTensor()\n",
    "        anchor = convert_tensor(anchor)\n",
    "        positive = convert_tensor(positive)\n",
    "        negative = convert_tensor(negative)\n",
    "        \n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_data: DataLoader, test_data: DataLoader, loss_fcn: nn.Module, epochs: int = 10, device: str = \"cpu\"):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Tensorboard logger\n",
    "    logger = SummaryWriter(\"./logs/Landmark V1.0\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        for i, (anchor, positive, negative) in tqdm(enumerate(train_data), f\"Epoch {epoch}\", unit=\"batch\"):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Send images to the device\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            anchor_features = model(anchor)\n",
    "            positive_features = model(positive)\n",
    "            negative_features = model(negative)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fcn(anchor_features, positive_features, negative_features)\n",
    "\n",
    "            # Log loss to tensorboard\n",
    "            logger.add_scalar(\"Triplet Loss\", loss, i)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the testing data\n",
    "        model.eval()\n",
    "\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (anchor, positive, negative) in tqdm(enumerate(test_data), \"Testing\", unit=\"batch\"):\n",
    "                anchor.to(model.device)\n",
    "                positive.to(model.device)\n",
    "                negative.to(model.device)\n",
    "\n",
    "                anchor_features = model(anchor)\n",
    "                positive_features = model(positive)\n",
    "                negative_features = model(negative)\n",
    "\n",
    "                #TODO: Add some more metrics to the validation loop (i.e. euclidean distance between a & p, a & n, etc...)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = loss_fcn(anchor_features, positive_features, negative_features)\n",
    "\n",
    "                validation_loss += loss\n",
    "\n",
    "        logger.add_scalar(\"Validation Loss\", validation_loss / len(test_data), epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch} Validation Loss: {validation_loss / len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = FashionDataset(\"data/DressCode\", \"data/DressCode/train_pairs.txt\")\n",
    "\n",
    "test_data = FashionDataset(\"data/DressCode\", \"data/DressCode/test_pairs_paired.txt\")\n",
    "\n",
    "\n",
    "# Define the training dataloader\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define the validation dataloader\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load the model\n",
    "model = models.resnet50()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 37batch [03:26,  5.57s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTripletMarginLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, test_data, loss_fcn, epochs, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fcn(anchor_features, positive_features, negative_features)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Log loss to tensorboard\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTriplet Loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\troyd\\Programs\\ECE379K\\image-atlas\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:393\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[0;32m    391\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[1;32m--> 393\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[1;32mc:\\Users\\troyd\\Programs\\ECE379K\\image-atlas\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:369\u001b[0m, in \u001b[0;36mscalar\u001b[1;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscalar\u001b[39m(name, tensor, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, new_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, double_precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Output a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    The generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m      ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmake_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    371\u001b[0m         tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    372\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\troyd\\Programs\\ECE379K\\image-atlas\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:23\u001b[0m, in \u001b[0;36mmake_np\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([x])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_prepare_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but numpy array, torch tensor, or caffe2 blob name are expected.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\troyd\\Programs\\ECE379K\\image-atlas\\.venv\\Lib\\site-packages\\torch\\utils\\tensorboard\\_convert_np.py:30\u001b[0m, in \u001b[0;36m_prepare_pytorch\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_pytorch\u001b[39m(x):\n\u001b[1;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, test_loader, nn.TripletMarginLoss(), epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
