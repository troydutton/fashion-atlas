{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x153787b3dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = [\n",
    "    \"upper_body\",\n",
    "    \"lower_body\",\n",
    "    \"dresses\"\n",
    "]\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, root: str, pairs: str) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((256, 192)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        # Root directory of the dataset\n",
    "        self.root = root\n",
    "\n",
    "        # Load in the paired data\n",
    "        self.data = pd.read_csv(pairs, delimiter='\\t', header=None, names=['model', 'garment', 'label']).head(1000)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "              return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        model, garment, label = self.data.iloc[index]\n",
    "        \n",
    "        # Load the images\n",
    "        anchor = Image.open(os.path.join(self.root, LABEL_MAP[label], \"images\", garment)).convert(\"RGB\")\n",
    "        positive = Image.open(os.path.join(self.root, LABEL_MAP[label], \"images\", model)).convert(\"RGB\")\n",
    "        \n",
    "        # Load the negative image\n",
    "        negative_index = random.randrange(0, len(self.data))\n",
    "        negative_model, negative_garment, negative_label = self.data.iloc[negative_index]\n",
    "        negative = Image.open(os.path.join(self.root, LABEL_MAP[negative_label], \"images\", negative_model)).convert(\"RGB\")\n",
    "\n",
    "        # Resize & convert to tensors\n",
    "        anchor = self.transforms(anchor)\n",
    "        positive = self.transforms(positive)\n",
    "        negative = self.transforms(negative)\n",
    "        \n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_data: DataLoader, test_data: DataLoader, loss_fcn: nn.Module, epochs: int = 10, device: str = \"cpu\"):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Tensorboard logger\n",
    "    logger = SummaryWriter(\"./logs/ResNet50\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        for i, (anchor, positive, negative) in tqdm(enumerate(train_data), f\"Epoch {epoch} Training\", unit=\"batch\", total=len(train_data)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Send images to the device\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            anchor_features = model(anchor)\n",
    "            positive_features = model(positive)\n",
    "            negative_features = model(negative)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fcn(anchor_features, positive_features, negative_features)\n",
    "\n",
    "            # Log loss to tensorboard\n",
    "            logger.add_scalar(\"Train/Triplet Loss\", loss, i + epoch * len(train_data))\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the testing data\n",
    "        model.eval()\n",
    "\n",
    "        validation_loss = 0.0\n",
    "        euclidean_distance_ap = 0.0\n",
    "        euclidean_distance_an = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (anchor, positive, negative) in tqdm(enumerate(test_data), f\"Epoch {epoch} Evaluation\", unit=\"batch\", total=len(test_data)):\n",
    "                # Send images to the device\n",
    "                anchor = anchor.to(device)\n",
    "                positive = positive.to(device)\n",
    "                negative = negative.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                anchor_features = model(anchor)\n",
    "                positive_features = model(positive)\n",
    "                negative_features = model(negative)\n",
    "\n",
    "                # Compute the loss\n",
    "                validation_loss += loss_fcn(anchor_features, positive_features, negative_features)\n",
    "\n",
    "                # Compute the Euclidean distance between anchor and positive features\n",
    "                euclidean_distance_ap += torch.norm(anchor_features - positive_features, dim=1).sum()\n",
    "\n",
    "                # Compute the Euclidean distance between anchor and negative features\n",
    "                euclidean_distance_an += torch.norm(anchor_features - negative_features, dim=1).sum()\n",
    "\n",
    "        logger.add_scalar(\"Test/Triplet Loss\", validation_loss / len(test_data), epoch)\n",
    "        logger.add_scalar(\"Test/Euclidean Distance Ratio (AN/AP)\", euclidean_distance_an / euclidean_distance_ap, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch} Validation Loss: {validation_loss / len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = FashionDataset(\"data/DressCode\", \"data/DressCode/train_pairs.txt\")\n",
    "\n",
    "test_data = FashionDataset(\"data/DressCode\", \"data/DressCode/test_pairs_paired.txt\")\n",
    "\n",
    "\n",
    "# Define the training dataloader\n",
    "train_loader = DataLoader(train_data, batch_size=48, shuffle=True)\n",
    "\n",
    "# Define the validation dataloader\n",
    "test_loader = DataLoader(test_data, batch_size=48, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = models.resnet50()\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training: 100%|██████████| 21/21 [00:25<00:00,  1.20s/batch]\n",
      "Epoch 0 Evaluation: 100%|██████████| 21/21 [00:18<00:00,  1.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Loss: 2.01607084274292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 21/21 [00:22<00:00,  1.07s/batch]\n",
      "Epoch 1 Evaluation: 100%|██████████| 21/21 [00:18<00:00,  1.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Loss: 0.8027896285057068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 21/21 [00:22<00:00,  1.08s/batch]\n",
      "Epoch 2 Evaluation: 100%|██████████| 21/21 [00:20<00:00,  1.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Loss: 0.7215956449508667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 21/21 [00:25<00:00,  1.20s/batch]\n",
      "Epoch 3 Evaluation: 100%|██████████| 21/21 [00:19<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Loss: 0.4434157907962799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 21/21 [00:22<00:00,  1.07s/batch]\n",
      "Epoch 4 Evaluation: 100%|██████████| 21/21 [00:19<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Loss: 0.4713684320449829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 21/21 [00:22<00:00,  1.07s/batch]\n",
      "Epoch 5 Evaluation: 100%|██████████| 21/21 [00:18<00:00,  1.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Loss: 0.4361904263496399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 21/21 [00:22<00:00,  1.06s/batch]\n",
      "Epoch 6 Evaluation: 100%|██████████| 21/21 [00:18<00:00,  1.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Loss: 0.3383471667766571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 21/21 [00:22<00:00,  1.07s/batch]\n",
      "Epoch 7 Evaluation: 100%|██████████| 21/21 [00:18<00:00,  1.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Loss: 0.42968982458114624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 21/21 [00:22<00:00,  1.09s/batch]\n",
      "Epoch 8 Evaluation: 100%|██████████| 21/21 [00:19<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Loss: 0.5334165096282959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 21/21 [00:22<00:00,  1.07s/batch]\n",
      "Epoch 9 Evaluation: 100%|██████████| 21/21 [00:19<00:00,  1.10batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Loss: 0.4470618665218353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, test_loader, nn.TripletMarginLoss(), epochs=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
